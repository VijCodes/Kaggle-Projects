{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Importing Modules","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os \nimport torch\nfrom torch import nn\nimport torch.nn.functional as F","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.866614Z","iopub.execute_input":"2023-07-19T14:16:53.867059Z","iopub.status.idle":"2023-07-19T14:16:53.873568Z","shell.execute_reply.started":"2023-07-19T14:16:53.867025Z","shell.execute_reply":"2023-07-19T14:16:53.872027Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/segment-anything-zip-file/segment-anything\")","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.887333Z","iopub.execute_input":"2023-07-19T14:16:53.887762Z","iopub.status.idle":"2023-07-19T14:16:53.909916Z","shell.execute_reply.started":"2023-07-19T14:16:53.887735Z","shell.execute_reply":"2023-07-19T14:16:53.908499Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import segment_anything as sam","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.912035Z","iopub.execute_input":"2023-07-19T14:16:53.912733Z","iopub.status.idle":"2023-07-19T14:16:53.919638Z","shell.execute_reply.started":"2023-07-19T14:16:53.912643Z","shell.execute_reply":"2023-07-19T14:16:53.918405Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#validation_meta = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation_metadata.json')\n#train_metadata = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/train_metadata.json')\nsample_submission = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.929874Z","iopub.execute_input":"2023-07-19T14:16:53.930313Z","iopub.status.idle":"2023-07-19T14:16:53.951600Z","shell.execute_reply.started":"2023-07-19T14:16:53.930280Z","shell.execute_reply":"2023-07-19T14:16:53.950681Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"#### Configuration","metadata":{}},{"cell_type":"code","source":"config = {\n    'batch_size': 8,\n    'learning_rate': 0.001,\n    'n_epochs': 10,\n    # Add any other hyperparameters you want to track\n}\n\n# Use the hyperparameters from the config dictionary\nbatch_size = config['batch_size']\nlearning_rate = config['learning_rate']\nn_epochs = config['n_epochs']","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.955085Z","iopub.execute_input":"2023-07-19T14:16:53.958700Z","iopub.status.idle":"2023-07-19T14:16:53.966311Z","shell.execute_reply.started":"2023-07-19T14:16:53.958666Z","shell.execute_reply":"2023-07-19T14:16:53.965243Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"#### Setting up lazy-loading and preprocessing functions","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\ndef getdata(obs_path):\n    bands_data = {}\n\n    # Load all band data\n    for filename in os.listdir(obs_path):\n        if \"band\" in filename:\n            band_name = filename.split('.')[0]  # get the name of the band (excluding the .npy extension)\n            file_path = os.path.join(obs_path, filename)  # full path of the file\n            band_data = np.load(file_path)  # load the band data\n            bands_data[band_name] = band_data  # store the band data in the dictionary\n    \n    # Load the aggregated contrail markings as labels\n    label_path = os.path.join(obs_path, 'human_pixel_masks.npy')\n    if os.path.exists(label_path):\n        labels = np.load(label_path)\n    else:\n        labels = None\n    return bands_data, labels\n\ndef get_ash_color_images(bands_data,get_mask_frame_only = False) -> np.array:\n    band11 = bands_data['band_11']\n    band14 = bands_data['band_14']\n    band15 = bands_data['band_15']\n    \n    if get_mask_frame_only:\n        band11 = band11[:,:,4]\n        band14 = band14[:,:,4]\n        band15 = band15[:,:,4]\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    return false_color\n\ndef preprocess_func(bands_data):\n    stacked_data = get_ash_color_images(bands_data,get_mask_frame_only = True)\n    stacked_data = stacked_data.transpose(2, 0, 1)\n    return stacked_data\n","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.971804Z","iopub.execute_input":"2023-07-19T14:16:53.972475Z","iopub.status.idle":"2023-07-19T14:16:53.992073Z","shell.execute_reply.started":"2023-07-19T14:16:53.972438Z","shell.execute_reply":"2023-07-19T14:16:53.991002Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"4\" face=\"verdana\">\n\n| **Band Number** | **Description** | **Additional Details** |\n| --- | --- | --- |\n| **Band 8** | \"Upper-Level Tropospheric Water Vapor\" Band | This band is helpful in tracking upper-level atmospheric moisture and jet stream winds, aiding in the forecasting of severe weather events and heavy rainfall. |\n| **Band 9** | \"Mid-Level Tropospheric Water Vapor\" Band | This band captures images of mid-tropospheric moisture and atmospheric motion, valuable for identifying features such as tropical cyclones and thunderstorms. |\n| **Band 10** | \"Lower-level Water Vapor\" Band | The lower-level water vapor band assists in identifying low-level moisture content, aiding in the prediction of fog, frost, and low clouds. |\n| **Band 11** | \"Cloud-Top Phase\" Band | This band helps to determine cloud phases (water, mixed, ice) and heights, crucial for aviation safety and general weather prediction. |\n| **Band 12** | \"Ozone Band\" | The ozone band detects ozone concentration in the atmosphere, offering insights into ozone layer health and aiding in the prediction of UV index and air quality. |\n| **Band 13** | \"Clean\" IR Longwave Window Band | Primarily used for detection of clouds at all levels, sea surface temperature, and rainfall. |\n| **Band 14** | IR Longwave Window Band | This band is used for surface and cloud top temperature estimates, identifying cloud types and cloud motion. |\n| **Band 15** | \"Dirty\" Longwave Window Band | Used for estimation of lower-tropospheric water vapor, volcanic ash detection, and for improved rainfall estimation. |\n| **Band 16** | \"CO2\" Longwave Infrared | This band aids in the estimation of cloud height and temperature, especially for high-level clouds. |\n\n</font>","metadata":{}},{"cell_type":"code","source":"class ContrailsData(Dataset):\n    def __init__(self, data_paths, preprocess_func, train_validation):\n        # Initialize your data, download, etc.\n        self.data_paths = data_paths\n        self.preprocess_func = preprocess_func\n        self.train_validation = train_validation\n    \n    def __len__(self):\n        return len(self.data_paths['path'])\n\n    def __getitem__(self, index):\n        obs_path = self.data_paths.iloc[index]['path']\n        bands_data, labels = getdata(obs_path)\n        data = self.preprocess_func(bands_data)\n        labels = labels.transpose(2, 0, 1)\n        labels = torch.from_numpy(labels)\n        labels = labels.float()\n        return data, labels\n\n\ndef get_data_paths(root_dir):\n    all_dirs = []\n    for path in os.listdir(root_dir):\n        full_path = os.path.join(root_dir, path)\n        if os.path.isdir(full_path):\n            all_dirs.append(full_path)\n    return pd.DataFrame(all_dirs, columns=['path'])\n\nroot_dir_train = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/train'\nroot_dir_validation = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation'\n\ntrain_data_paths = get_data_paths(root_dir_train)\nvalidation_data_paths = get_data_paths(root_dir_validation)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:16:53.996835Z","iopub.execute_input":"2023-07-19T14:16:53.999448Z","iopub.status.idle":"2023-07-19T14:17:20.909511Z","shell.execute_reply.started":"2023-07-19T14:16:53.999414Z","shell.execute_reply":"2023-07-19T14:17:20.908265Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"train_dataset = ContrailsData(train_data_paths, preprocess_func, 'train')\nvalidation_dataset = ContrailsData(validation_data_paths, preprocess_func, 'validation')\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:17:20.913366Z","iopub.execute_input":"2023-07-19T14:17:20.914304Z","iopub.status.idle":"2023-07-19T14:17:20.925593Z","shell.execute_reply.started":"2023-07-19T14:17:20.914268Z","shell.execute_reply":"2023-07-19T14:17:20.924540Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"#### Defining Models\n\n*  SimpleConv2D\n*  UNet\n*  Residual Attention Unet","metadata":{}},{"cell_type":"code","source":"class SimpleConv2D(nn.Module):\n    def __init__(self):\n        super(SimpleConv2D, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        \n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n\n        self.conv_final = nn.Conv2d(256, 1, kernel_size=1, stride=1)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.conv_final(x)\n        \n        # Add a Sigmoid activation function as the last layer\n        #x = torch.sigmoid(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:51.860090Z","iopub.execute_input":"2023-07-19T14:21:51.860836Z","iopub.status.idle":"2023-07-19T14:21:51.868913Z","shell.execute_reply.started":"2023-07-19T14:21:51.860806Z","shell.execute_reply":"2023-07-19T14:21:51.867934Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n        \n        self.upconv5 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        \n        self.conv6 = nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1)\n        self.conv7 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n        self.conv8 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n        self.conv9 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.conv_final = nn.Conv2d(64, 1, kernel_size=1)\n\n    def forward(self,x):\n        x1 = F.relu(self.conv1(x))\n        x = F.max_pool2d(x1,kernel_size=(2))\n        \n        x2 = F.relu(self.conv2(x))\n        x = F.max_pool2d(x2,kernel_size=(2))\n        \n        x3 = F.relu(self.conv3(x))\n        x = F.max_pool2d(x3,kernel_size=(2))\n        \n        x4 = F.relu(self.conv4(x))\n        x = F.max_pool2d(x4,kernel_size=(2))\n        \n        x5 = F.relu(self.conv5(x))\n        \n        x6 = torch.cat([x4,self.upconv5(x5)],dim=-3)\n        x6 = F.relu(self.conv6(x6))\n        \n        x7 = torch.cat([x3,self.upconv4(x6)],dim=-3)\n        x7 = F.relu(self.conv7(x7))\n        \n        x8 = torch.cat([x2,self.upconv3(x7)],dim=-3)\n        x8 = F.relu(self.conv8(x8))\n        \n        x9 = torch.cat([x1,self.upconv2(x8)],dim=-3)\n        x9 = F.relu(self.conv9(x9))\n        \n        out=self.conv_final(x9)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:51.885837Z","iopub.execute_input":"2023-07-19T14:21:51.887325Z","iopub.status.idle":"2023-07-19T14:21:51.903599Z","shell.execute_reply.started":"2023-07-19T14:21:51.887291Z","shell.execute_reply":"2023-07-19T14:21:51.902569Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"### Residual Attention Unet","metadata":{}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom torch import nn\nimport random\n\nrandom.seed(0)\nnp.random.seed(0)\ntorch.manual_seed(0)\n\ndef conv3x3(in_planes, out_planes, stride=1):\n    \"3x3 convolution with padding\"\n    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n                     padding=1, bias=False)\n\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n           \n        self.fc = nn.Sequential(nn.Conv2d(in_planes, in_planes // 16, 1, bias=False),\n                               nn.ReLU(),\n                               nn.Conv2d(in_planes // 16, in_planes, 1, bias=False))\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc(self.avg_pool(x))\n        max_out = self.fc(self.max_pool(x))\n        out = avg_out + max_out\n        return self.sigmoid(out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        x = self.conv1(x)\n        return self.sigmoid(x)\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, inputChannel, outputChannel, stride=1, downsample=None):\n        super(ResidualBlock, self).__init__()\n        self.conv1 = conv3x3(inputChannel, outputChannel, stride)\n        self.bn1 = nn.BatchNorm2d(outputChannel)\n        self.relu = nn.ReLU(inplace=True)\n        self.conv2 = conv3x3(outputChannel, outputChannel)\n        self.bn2 = nn.BatchNorm2d(outputChannel)\n        self.downsample = downsample\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n        \n    def forward(self, x):\n        residual = x\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n        out = self.conv2(out)\n        out = self.bn2(out)\n        if self.downsample:\n            residual = self.downsample(x)\n        out += residual\n        out = self.relu(out)\n        caOutput = self.ca(out)\n        out = caOutput * out\n        saOutput = self.sa(out)\n        out = saOutput * out\n        return out, saOutput\n\nclass BasicDownSample(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.AvgPool2d(2)\n        )\n    \n    def forward(self,x):\n        x = self.convolution(x)\n        return x\n\nclass DownSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.AvgPool2d(2)\n        )\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self,x):\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\nclass BasicUpSample(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2)\n        )\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n    \n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.convolution(x)\n        return x\n    \nclass UpSampleWithAttention(nn.Module):\n    def __init__(self, inputChannel, outputChannel):\n        super().__init__()\n        self.convolution = nn.Sequential(\n            nn.Conv2d(inputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2),\n            nn.Conv2d(outputChannel, outputChannel, kernel_size=3, padding=1),\n            nn.BatchNorm2d(outputChannel),\n            nn.LeakyReLU(0.2)\n        )\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n        self.ca = ChannelAttention(outputChannel)\n        self.sa = SpatialAttention()\n    \n    def forward(self, x):\n        x = self.upsample(x)\n        x = self.convolution(x)\n        caOutput = self.ca(x)\n        x = caOutput * x\n        saOutput = self.sa(x)\n        x = saOutput * x\n        return x, saOutput\n\nclass UNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = BasicDownSample(inputChannel, 32)\n    self.downsample2 = BasicDownSample(32, 64)\n    self.downsample3 = BasicDownSample(64, 128)\n    self.downsample4 = BasicDownSample(128, 256)\n    self.downsample5 = BasicDownSample(256, 512)\n\n    self.upsample1 = BasicUpSample(512, 256)\n    self.upsample2 = BasicUpSample(512, 128)\n    self.upsample3 = BasicUpSample(256, 64)\n    self.upsample4 = BasicUpSample(128, 32)\n    self.upsample5 = BasicUpSample(64, 32)\n    self.classification = self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128 = self.downsample1(x)\n    scale64 = self.downsample2(scale128)\n    scale32 = self.downsample3(scale64)\n    scale16 = self.downsample4(scale32)\n    scale8 = self.downsample5(scale16)\n    upscale16 = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32 = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64 = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128 = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256 = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput\n\nclass AttentionUNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n    self.downsample2 = DownSampleWithAttention(32, 64)\n    self.downsample3 = DownSampleWithAttention(64, 128)\n    self.downsample4 = DownSampleWithAttention(128, 256)\n    self.downsample5 = DownSampleWithAttention(256, 512)\n\n    self.upsample1 = UpSampleWithAttention(512, 256)\n    self.upsample2 = UpSampleWithAttention(512, 128)\n    self.upsample3 = UpSampleWithAttention(256, 64)\n    self.upsample4 = UpSampleWithAttention(128, 32)\n    self.upsample5 = UpSampleWithAttention(64, 32)\n    self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128, sa128down = self.downsample1(x)\n    scale64, sa64down = self.downsample2(scale128)\n    scale32, sa32down = self.downsample3(scale64)\n    scale16, sa64down = self.downsample4(scale32)\n    scale8, sa8down = self.downsample5(scale16)\n    upscale16, sa16up = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32, sa32up = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64, sa64up = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128, sa128up = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256, sa256up = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput\n\nclass ResidualAttentionUNet(nn.Module):\n  def __init__(self, inputChannel, outputChannel):\n    super().__init__()\n    self.downsample1 = DownSampleWithAttention(inputChannel, 32)\n    self.downsample2 = DownSampleWithAttention(32, 64)\n    self.downsample3 = DownSampleWithAttention(64, 128)\n    self.downsample4 = DownSampleWithAttention(128, 256)\n    self.downsample5 = DownSampleWithAttention(256, 512)\n\n    self.residualBlock1 = ResidualBlock(512, 512)\n    self.residualBlock2 = ResidualBlock(512, 512)\n    self.residualBlock3 = ResidualBlock(512, 512)\n\n    self.upsample1 = UpSampleWithAttention(512, 256)\n    self.upsample2 = UpSampleWithAttention(512, 128)\n    self.upsample3 = UpSampleWithAttention(256, 64)\n    self.upsample4 = UpSampleWithAttention(128, 32)\n    self.upsample5 = UpSampleWithAttention(64, 32)\n    self.classification = nn.Sequential(\n            nn.Conv2d(32, outputChannel, kernel_size=1),\n        )\n\n  def forward(self, x):\n    scale128, sa128down = self.downsample1(x)\n    scale64, sa64down = self.downsample2(scale128)\n    scale32, sa32down = self.downsample3(scale64)\n    scale16, sa64down = self.downsample4(scale32)\n    scale8, sa8down = self.downsample5(scale16)\n    scale8, sa8down = self.residualBlock1(scale8)\n    scale8, sa8down = self.residualBlock2(scale8)\n    scale8, sa8down = self.residualBlock3(scale8)\n    upscale16, sa16up = self.upsample1(scale8)\n    upscale16 = torch.cat([upscale16, scale16], dim=1)\n    upscale32, sa32up = self.upsample2(upscale16)\n    upscale32 = torch.cat([upscale32, scale32], dim=1)\n    upscale64, sa64up = self.upsample3(upscale32)\n    upscale64 = torch.cat([upscale64, scale64], dim=1)\n    upscale128, sa128up = self.upsample4(upscale64)\n    upscale128 = torch.cat([upscale128, scale128], dim=1)\n    upscale256, sa256up = self.upsample5(upscale128)\n    finaloutput = self.classification(upscale256)\n    return finaloutput","metadata":{"execution":{"iopub.status.busy":"2023-07-19T14:21:51.905377Z","iopub.execute_input":"2023-07-19T14:21:51.905697Z","iopub.status.idle":"2023-07-19T14:21:51.965269Z","shell.execute_reply.started":"2023-07-19T14:21:51.905674Z","shell.execute_reply":"2023-07-19T14:21:51.964448Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"#### Training\n\n*  Had to decrease batch size and empty cache because of memory issues. \n","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n# Define the device for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize your model\n#model = SimpleConv2D().to(device)\n#model  = UNet().to(device)\nmodel  = ResidualAttentionUNet(inputChannel = 3, outputChannel = 1).to(device)\n\n# Load the saved model state\n#model.load_state_dict(torch.load('ResAttUnet.pth'))\n\nmodel.load_state_dict(torch.load('/kaggle/input/resattunet-model-state/ResAttUnet.pth'))\n\n# Define loss function\ncriterion = nn.BCEWithLogitsLoss()\n\n# Define optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\n# Prepare your data loaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n\n# Training loop\nfor epoch in range(n_epochs):\n    model.train()\n    running_loss = 0\n    batches = 0\n    for images, labels in train_dataloader:\n        torch.cuda.empty_cache()\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        #print(images.shape)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n        batches+=1\n        #print(f'batch:{batches} completed')\n        if batches%100 == 0: print(f'batches ran: {batches}')\n\n    epoch_loss = running_loss / len(train_dataloader.dataset)\n    print('Train Loss: {:.4f}'.format(epoch_loss))\n\n    # Validation loop\n    model.eval()\n    with torch.no_grad():\n        running_loss = 0\n        for images, labels in validation_dataloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * images.size(0)\n\n        epoch_loss = running_loss / len(validation_dataloader.dataset)\n        print('Validation Loss: {:.4f}'.format(epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T17:54:08.501792Z","iopub.status.idle":"2023-07-19T17:54:08.502567Z","shell.execute_reply.started":"2023-07-19T17:54:08.502307Z","shell.execute_reply":"2023-07-19T17:54:08.502334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Saving the current state of the model","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'ResAttUnet.pth')","metadata":{"execution":{"iopub.status.busy":"2023-07-19T17:54:15.744500Z","iopub.execute_input":"2023-07-19T17:54:15.744905Z","iopub.status.idle":"2023-07-19T17:54:16.003132Z","shell.execute_reply.started":"2023-07-19T17:54:15.744872Z","shell.execute_reply":"2023-07-19T17:54:16.002018Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"model.eval()\nwith torch.no_grad():\n    running_loss = 0\n    for images, labels in validation_dataloader:\n        images = images.to(device)\n        labels = labels.to(device)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        running_loss += loss.item() * images.size(0)\n\n    epoch_loss = running_loss / len(validation_dataloader.dataset)\n    print('Validation Loss: {:.4f}'.format(epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-19T18:25:49.276076Z","iopub.execute_input":"2023-07-19T18:25:49.276485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Finding Optimal Dice Coefficient","metadata":{}},{"cell_type":"code","source":"class DiceThresholdTester:\n    \n    def __init__(self, model: nn.Module, data_loader: torch.utils.data.DataLoader):\n        self.model = model\n        self.data_loader = data_loader\n        self.cumulative_mask_pred = []\n        self.cumulative_mask_true = []\n        \n    def precalculate_prediction(self) -> None:\n        sigmoid = nn.Sigmoid()\n        for images, mask_true in self.data_loader:\n            if torch.cuda.is_available():\n                images = images.cuda()\n\n            mask_pred = sigmoid(model.forward(images))\n\n            self.cumulative_mask_pred.append(mask_pred.cpu().detach().numpy())\n            self.cumulative_mask_true.append(mask_true.cpu().detach().numpy())\n            \n        self.cumulative_mask_pred = np.concatenate(self.cumulative_mask_pred, axis=0)\n        self.cumulative_mask_true = np.concatenate(self.cumulative_mask_true, axis=0)\n\n        self.cumulative_mask_pred = torch.flatten(torch.from_numpy(self.cumulative_mask_pred))\n        self.cumulative_mask_true = torch.flatten(torch.from_numpy(self.cumulative_mask_true))\n    \n    def test_threshold(self, threshold: float) -> float:\n        _dice = Dice(use_sigmoid=False)\n        after_threshold = np.zeros(self.cumulative_mask_pred.shape)\n        after_threshold[self.cumulative_mask_pred[:] > threshold] = 1\n        after_threshold[self.cumulative_mask_pred[:] < threshold] = 0\n        after_threshold = torch.flatten(torch.from_numpy(after_threshold))\n        return _dice(self.cumulative_mask_true, after_threshold).item()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dice_threshold_tester = DiceThresholdTester(model, validation_dataloader)\ndice_threshold_tester.precalculate_prediction()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresholds_to_test = [round(x * 0.01, 2) for x in range(101)]\n\noptim_threshold = 0.975\nbest_dice_score = -1\n\nthresholds = []\ndice_scores = []\n\nfor t in thresholds_to_test:\n    dice_score = dice_threshold_tester.test_threshold(t)\n    if dice_score > best_dice_score:\n        best_dice_score = dice_score\n        optim_threshold = t\n    \n    thresholds.append(t)\n    dice_scores.append(dice_score)\n    \nprint(f'Best Threshold: {optim_threshold} with dice: {best_dice_score}')\ndf_threshold_data = pd.DataFrame({'Threshold': thresholds, 'Dice Score': dice_scores})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}