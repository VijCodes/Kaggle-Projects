{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"#### Importing Modules","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os \nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n##for dirname, _, filenames in os.walk('/kaggle/input'):\n  #  for filename in filenames:\n   #     print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r /kaggle/input/segment-anything-zip-file/segment-anything /kaggle/input/segment-anything","metadata":{"execution":{"iopub.status.busy":"2023-07-18T22:25:14.802809Z","iopub.execute_input":"2023-07-18T22:25:14.803352Z","iopub.status.idle":"2023-07-18T22:25:15.913523Z","shell.execute_reply.started":"2023-07-18T22:25:14.803308Z","shell.execute_reply":"2023-07-18T22:25:15.911977Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cp: cannot create directory '/kaggle/input/segment-anything': Read-only file system\n","output_type":"stream"}]},{"cell_type":"code","source":"#validation_meta = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation_metadata.json')\n#train_metadata = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/train_metadata.json')\nsample_submission = pd.read_csv(r'/kaggle/input/google-research-identify-contrails-reduce-global-warming/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:58:52.603443Z","iopub.execute_input":"2023-07-16T14:58:52.604462Z","iopub.status.idle":"2023-07-16T14:58:52.624257Z","shell.execute_reply.started":"2023-07-16T14:58:52.604425Z","shell.execute_reply":"2023-07-16T14:58:52.623109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Configuration","metadata":{}},{"cell_type":"code","source":"config = {\n    'batch_size': 8,\n    'learning_rate': 0.001,\n    'n_epochs': 10,\n    # Add any other hyperparameters you want to track\n}\n\n# Use the hyperparameters from the config dictionary\nbatch_size = config['batch_size']\nlearning_rate = config['learning_rate']\nn_epochs = config['n_epochs']","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:58:52.629991Z","iopub.execute_input":"2023-07-16T14:58:52.633377Z","iopub.status.idle":"2023-07-16T14:58:52.642494Z","shell.execute_reply.started":"2023-07-16T14:58:52.633342Z","shell.execute_reply":"2023-07-16T14:58:52.641297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Setting up lazy-loading and preprocessing functions","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\n_T11_BOUNDS = (243, 303)\n_CLOUD_TOP_TDIFF_BOUNDS = (-4, 5)\n_TDIFF_BOUNDS = (-4, 2)\n\ndef normalize_range(data, bounds):\n    \"\"\"Maps data to the range [0, 1].\"\"\"\n    return (data - bounds[0]) / (bounds[1] - bounds[0])\n\ndef getdata(obs_path):\n    bands_data = {}\n\n    # Load all band data\n    for filename in os.listdir(obs_path):\n        if \"band\" in filename:\n            band_name = filename.split('.')[0]  # get the name of the band (excluding the .npy extension)\n            file_path = os.path.join(obs_path, filename)  # full path of the file\n            band_data = np.load(file_path)  # load the band data\n            bands_data[band_name] = band_data  # store the band data in the dictionary\n    \n    # Load the aggregated contrail markings as labels\n    label_path = os.path.join(obs_path, 'human_pixel_masks.npy')\n    if os.path.exists(label_path):\n        labels = np.load(label_path)\n    else:\n        labels = None\n    return bands_data, labels\n\ndef get_ash_color_images(bands_data,get_mask_frame_only = False) -> np.array:\n    band11 = bands_data['band_11']\n    band14 = bands_data['band_14']\n    band15 = bands_data['band_15']\n    \n    if get_mask_frame_only:\n        band11 = band11[:,:,4]\n        band14 = band14[:,:,4]\n        band15 = band15[:,:,4]\n\n    r = normalize_range(band15 - band14, _TDIFF_BOUNDS)\n    g = normalize_range(band14 - band11, _CLOUD_TOP_TDIFF_BOUNDS)\n    b = normalize_range(band14, _T11_BOUNDS)\n    false_color = np.clip(np.stack([r, g, b], axis=2), 0, 1)\n    return false_color\n\ndef preprocess_func(bands_data):\n    stacked_data = get_ash_color_images(bands_data,get_mask_frame_only = True)\n    stacked_data = stacked_data.transpose(2, 0, 1)\n    return stacked_data\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:58:52.645789Z","iopub.execute_input":"2023-07-16T14:58:52.646579Z","iopub.status.idle":"2023-07-16T14:58:52.665422Z","shell.execute_reply.started":"2023-07-16T14:58:52.646537Z","shell.execute_reply":"2023-07-16T14:58:52.664156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<font size=\"4\" face=\"verdana\">\n\n| **Band Number** | **Description** | **Additional Details** |\n| --- | --- | --- |\n| **Band 8** | \"Upper-Level Tropospheric Water Vapor\" Band | This band is helpful in tracking upper-level atmospheric moisture and jet stream winds, aiding in the forecasting of severe weather events and heavy rainfall. |\n| **Band 9** | \"Mid-Level Tropospheric Water Vapor\" Band | This band captures images of mid-tropospheric moisture and atmospheric motion, valuable for identifying features such as tropical cyclones and thunderstorms. |\n| **Band 10** | \"Lower-level Water Vapor\" Band | The lower-level water vapor band assists in identifying low-level moisture content, aiding in the prediction of fog, frost, and low clouds. |\n| **Band 11** | \"Cloud-Top Phase\" Band | This band helps to determine cloud phases (water, mixed, ice) and heights, crucial for aviation safety and general weather prediction. |\n| **Band 12** | \"Ozone Band\" | The ozone band detects ozone concentration in the atmosphere, offering insights into ozone layer health and aiding in the prediction of UV index and air quality. |\n| **Band 13** | \"Clean\" IR Longwave Window Band | Primarily used for detection of clouds at all levels, sea surface temperature, and rainfall. |\n| **Band 14** | IR Longwave Window Band | This band is used for surface and cloud top temperature estimates, identifying cloud types and cloud motion. |\n| **Band 15** | \"Dirty\" Longwave Window Band | Used for estimation of lower-tropospheric water vapor, volcanic ash detection, and for improved rainfall estimation. |\n| **Band 16** | \"CO2\" Longwave Infrared | This band aids in the estimation of cloud height and temperature, especially for high-level clouds. |\n\n</font>","metadata":{}},{"cell_type":"code","source":"class ContrailsData(Dataset):\n    def __init__(self, data_paths, preprocess_func, train_validation):\n        # Initialize your data, download, etc.\n        self.data_paths = data_paths\n        self.preprocess_func = preprocess_func\n        self.train_validation = train_validation\n    \n    def __len__(self):\n        return len(self.data_paths['path'])\n\n    def __getitem__(self, index):\n        obs_path = self.data_paths.iloc[index]['path']\n        bands_data, labels = getdata(obs_path)\n        data = self.preprocess_func(bands_data)\n        labels = labels.transpose(2, 0, 1)\n        labels = torch.from_numpy(labels)\n        labels = labels.float()\n        return data, labels\n\n\ndef get_data_paths(root_dir):\n    all_dirs = []\n    for path in os.listdir(root_dir):\n        full_path = os.path.join(root_dir, path)\n        if os.path.isdir(full_path):\n            all_dirs.append(full_path)\n    return pd.DataFrame(all_dirs, columns=['path'])\n\nroot_dir_train = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/train'\nroot_dir_validation = '/kaggle/input/google-research-identify-contrails-reduce-global-warming/validation'\n\ntrain_data_paths = get_data_paths(root_dir_train)\nvalidation_data_paths = get_data_paths(root_dir_validation)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:58:52.667227Z","iopub.execute_input":"2023-07-16T14:58:52.667932Z","iopub.status.idle":"2023-07-16T14:59:10.516245Z","shell.execute_reply.started":"2023-07-16T14:58:52.667897Z","shell.execute_reply":"2023-07-16T14:59:10.515217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ContrailsData(train_data_paths, preprocess_func, 'train')\nvalidation_dataset = ContrailsData(validation_data_paths, preprocess_func, 'validation')\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:59:10.517955Z","iopub.execute_input":"2023-07-16T14:59:10.518673Z","iopub.status.idle":"2023-07-16T14:59:10.527439Z","shell.execute_reply.started":"2023-07-16T14:59:10.518636Z","shell.execute_reply":"2023-07-16T14:59:10.526548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(train_loader)\n","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:59:10.529155Z","iopub.execute_input":"2023-07-16T14:59:10.529953Z","iopub.status.idle":"2023-07-16T14:59:12.390214Z","shell.execute_reply.started":"2023-07-16T14:59:10.529918Z","shell.execute_reply":"2023-07-16T14:59:12.389034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'''shape of input: {data.shape}\nshape of labels: {labels.shape}''')","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:59:12.391640Z","iopub.execute_input":"2023-07-16T14:59:12.391970Z","iopub.status.idle":"2023-07-16T14:59:12.397053Z","shell.execute_reply.started":"2023-07-16T14:59:12.391939Z","shell.execute_reply":"2023-07-16T14:59:12.396201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Defining Models\n\n*  Yet to try advanced Models","metadata":{}},{"cell_type":"code","source":"class SimpleConv2D(nn.Module):\n    def __init__(self):\n        super(SimpleConv2D, self).__init__()\n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        \n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n\n        self.conv_final = nn.Conv2d(256, 1, kernel_size=1, stride=1)\n        \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv3(x))\n        x = self.conv_final(x)\n        \n        # Add a Sigmoid activation function as the last layer\n        #x = torch.sigmoid(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:59:12.398586Z","iopub.execute_input":"2023-07-16T14:59:12.399274Z","iopub.status.idle":"2023-07-16T14:59:12.416219Z","shell.execute_reply.started":"2023-07-16T14:59:12.399241Z","shell.execute_reply":"2023-07-16T14:59:12.415227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class UNet(nn.Module):\n    def __init__(self):\n        super(UNet, self).__init__()\n        \n        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n        self.conv4 = nn.Conv2d(256, 512, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(512, 1024, kernel_size=3, stride=1, padding=1)\n        \n        self.upconv5 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n        self.upconv4 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n        self.upconv3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n        self.upconv2 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n        \n        self.conv6 = nn.Conv2d(1024, 512, kernel_size=3, stride=1, padding=1)\n        self.conv7 = nn.Conv2d(512, 256, kernel_size=3, stride=1, padding=1)\n        self.conv8 = nn.Conv2d(256, 128, kernel_size=3, stride=1, padding=1)\n        self.conv9 = nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.conv_final = nn.Conv2d(64, 1, kernel_size=1)\n\n    def forward(self,x):\n        x1 = F.relu(self.conv1(x))\n        x = F.max_pool2d(x1,kernel_size=(2))\n        \n        x2 = F.relu(self.conv2(x))\n        x = F.max_pool2d(x2,kernel_size=(2))\n        \n        x3 = F.relu(self.conv3(x))\n        x = F.max_pool2d(x3,kernel_size=(2))\n        \n        x4 = F.relu(self.conv4(x))\n        x = F.max_pool2d(x4,kernel_size=(2))\n        \n        x5 = F.relu(self.conv5(x))\n        \n        x6 = torch.cat([x4,self.upconv5(x5)],dim=-3)\n        x6 = F.relu(self.conv6(x6))\n        \n        x7 = torch.cat([x3,self.upconv4(x6)],dim=-3)\n        x7 = F.relu(self.conv7(x7))\n        \n        x8 = torch.cat([x2,self.upconv3(x7)],dim=-3)\n        x8 = F.relu(self.conv8(x8))\n        \n        x9 = torch.cat([x1,self.upconv2(x8)],dim=-3)\n        x9 = F.relu(self.conv9(x9))\n        \n        out=self.conv_final(x9)\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2023-07-16T14:59:12.421380Z","iopub.execute_input":"2023-07-16T14:59:12.421637Z","iopub.status.idle":"2023-07-16T14:59:12.438556Z","shell.execute_reply.started":"2023-07-16T14:59:12.421614Z","shell.execute_reply":"2023-07-16T14:59:12.437683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Training\n\n*  Had to decrease batch size and empty cache because of memory issues. \n","metadata":{}},{"cell_type":"code","source":"import torch.nn.functional as F\n# Define the device for training\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# Initialize your model\n#model = SimpleConv2D().to(device)\nmodel  = UNet().to(device)\n\n# Define loss function\ncriterion = nn.BCEWithLogitsLoss()\n\n# Define optimizer\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\n\n# Prepare your data loaders\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nvalidation_dataloader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n\n# Training loop\nfor epoch in range(n_epochs):\n    model.train()\n    running_loss = 0\n    batches = 0\n    for images, labels in train_dataloader:\n        torch.cuda.empty_cache()\n        images = images.to(device)\n        labels = labels.to(device)\n        optimizer.zero_grad()\n        #print(images.shape)\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        running_loss += loss.item() * images.size(0)\n        batches+=1\n        if batches%100 == 0: print(f'batches ran: {batches}')\n\n    epoch_loss = running_loss / len(train_dataloader.dataset)\n    print('Train Loss: {:.4f}'.format(epoch_loss))\n\n    # Validation loop\n    model.eval()\n    with torch.no_grad():\n        running_loss = 0\n        for images, labels in validation_dataloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            running_loss += loss.item() * images.size(0)\n\n        epoch_loss = running_loss / len(validation_dataloader.dataset)\n        print('Validation Loss: {:.4f}'.format(epoch_loss))","metadata":{"execution":{"iopub.status.busy":"2023-07-16T15:05:16.046899Z","iopub.execute_input":"2023-07-16T15:05:16.047297Z","iopub.status.idle":"2023-07-16T15:17:03.423032Z","shell.execute_reply.started":"2023-07-16T15:05:16.047264Z","shell.execute_reply":"2023-07-16T15:17:03.416698Z"},"trusted":true},"execution_count":null,"outputs":[]}]}